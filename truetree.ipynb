{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In machine learning classification problems, there are often too many factors on the basis of which the final classification is done. \n",
    "These factors are basically variables called features. \n",
    "The higher the number of features, the harder it gets to visualize the training set and then work on it. \n",
    "Sometimes, most of these features are correlated and hence redundant. \n",
    "This is where dimensionality reduction algorithms come into play. \n",
    "Dimensionality reduction is the process of reducing the number of random variables under consideration, by obtaining a set of principal variables.\n",
    "It can be divided into feature selection and feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This for checking duplicates in a dataset\n",
    "df.duplicated()\n",
    "##This is a for checking in a particular column\n",
    "df.duplicated('col1')\n",
    "## This a for removing a duplicates in dataset\n",
    "df.drop_duplicates()\n",
    "### This is for removing a diplicate in particular column\n",
    "df.drop_duplicates(['col1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
